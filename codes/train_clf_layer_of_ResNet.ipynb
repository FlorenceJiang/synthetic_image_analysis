{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_clf_layer_of_ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT9ZEMC7W3ru"
      },
      "source": [
        "This notebook trains only the classification layer of the ResNet50 while keep the backbone frozon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS_IhnDLylZ2"
      },
      "source": [
        "# Mount with GDrive + connect to GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07gqChUZB5f-",
        "outputId": "cb8c0d0d-0bb7-4a17-e353-6236f87c7c45"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec  9 20:50:24 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZHk6Kt7yUCk"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fK7fyHPyaZp"
      },
      "source": [
        "%%capture\n",
        "# %%capture suppress the output of following !pip as they are tedious\n",
        "!pip3 install pyyaml==5.1 pycocotools>=2.0.1 ipython\n",
        "!pip3 install torch torchvision tensorflow \n",
        "!python3 -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip3 install Pillow\n",
        "!pip3 install pandas\n",
        "!pip3 install scikit-learn funcy\n",
        "!pip install awscli\n",
        "\n",
        "# Check if tensorboard is installed, otherwise install it\n",
        "!if [[ $(pip3 list | grep -c tensorboard) -eq 0 ]]; then pip3 install tensorboard; else echo \"tensorboard already installed\"; fi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rp3Cac4yzFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9e2368-77f5-4238-fb8f-f8fab180644d"
      },
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "from urllib import request\n",
        "import pandas as pd\n",
        "import os, json, shutil, cv2, random, datetime, torch, torchvision\n",
        "from shutil import copyfile\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from IPython.display import Image as IImage\n",
        "from IPython.display import display, HTML\n",
        "from IPython.display import IFrame\n",
        "import json, funcy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib import rcParams\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4KM9xmOQ0s0",
        "outputId": "e4174822-7395-41e7-e060-539a3d04604e"
      },
      "source": [
        "print(PIL.PILLOW_VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS1MaWi9NhJT",
        "outputId": "da24b081-2e09-43f7-e53c-0a105c5af980"
      },
      "source": [
        "cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmvPpEMiyeKq",
        "outputId": "a7dc64a4-fa30-41b5-b064-5d2a574ce649"
      },
      "source": [
        "!git clone https://github.com/myc159/Deep-Taylor-Decomposition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Deep-Taylor-Decomposition'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 101 (delta 26), reused 82 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (101/101), 1.79 MiB | 616.00 KiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0aIpqEw23_Z",
        "outputId": "c27431c4-247f-4538-f354-c17aeb73e8c4"
      },
      "source": [
        "% cd Deep-Taylor-Decomposition/ \n",
        "# must go into Deep-Taylor-Decomposition/ so 'from model ... ' in the next cell can be executed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Deep-Taylor-Decomposition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2h0TrAPypAb",
        "outputId": "78ab5d08-5f4f-43fe-f03e-7f72c5728529"
      },
      "source": [
        "# import argparse\n",
        "import logging\n",
        "import logging.handlers\n",
        "import pdb\n",
        "\n",
        "from model import *\n",
        "from model import saliency_mapping as sa_map\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from tqdm import tqdm \n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import requests\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 1\n",
        "# random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import OrderedDict\n",
        "from model.resnet import BasicBlock, Bottleneck\n",
        "\n",
        "try:\n",
        "    from torch.hub import load_state_dict_from_url\n",
        "except ImportError:\n",
        "    from torch.utils.model_zoo import load_url as load_state_dict_from_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi5doSJGNqT4"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC8st7mqJ1jB"
      },
      "source": [
        "civil_role_real_test_coco_path = \"/content/drive/MyDrive/111 Rendered.ai/RarePlanes/datasets/coco_data/civil_role_real_test_coco.json\"\n",
        "civil_role_real_test_images_path = \"/content/drive/MyDrive/111 Rendered.ai/RarePlanes/datasets/real/civil_test/\"\n",
        "role_model_dir = \"/content/drive/MyDrive/111 Rendered.ai/RarePlanes/models/model_0023999.pth\"\n",
        "models_file = \"/content/drive/MyDrive/111 Rendered.ai/RarePlanes/models/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZCt6cyP9cBm",
        "outputId": "14963e67-e422-4388-9f91-5e2f62877cca"
      },
      "source": [
        "# register data\n",
        "register_coco_instances(\"civil_test\", {}, civil_role_real_test_coco_path, civil_role_real_test_images_path)\n",
        "satrgb_metadata = MetadataCatalog.get(\"civil_test\")\n",
        "test_dicts = DatasetCatalog.get(\"civil_test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/09 20:50:49 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[12/09 20:50:49 d2.data.datasets.coco]: \u001b[0mLoaded 2601 images in COCO format from /content/drive/MyDrive/111 Rendered.ai/RarePlanes/datasets/coco_data/civil_role_real_test_coco.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7jMhR1G9uzH",
        "outputId": "497170f8-0464-4872-b92d-4b4ef1da5370"
      },
      "source": [
        "def load_coco_data(civil_role_real_test_coco_path):\n",
        "    test_json_dir = civil_role_real_test_coco_path\n",
        "    print(\"test json loc:\", civil_role_real_test_coco_path)\n",
        "    with open(test_json_dir) as json_file:\n",
        "        civil_role_real_test_coco = json.load(json_file)\n",
        "    print(civil_role_real_test_coco.keys())\n",
        "    print(\"Num images in civil role real test         : {}\".format(len(civil_role_real_test_coco['images'])))\n",
        "    print(\"classes in civil role real test        : {}\".format(civil_role_real_test_coco['categories']))\n",
        "    print(\"Num bbox/instances in civil role real test : {}\".format(len(civil_role_real_test_coco['annotations'])))\n",
        "    return civil_role_real_test_coco\n",
        "\n",
        "def load_model(role_model_dir):\n",
        "    return torch.load(role_model_dir)\n",
        "    print(role_model_pth['model'][\"roi_heads.box_predictor.cls_score.weight\"].shape)\n",
        "    print(role_model_pth['model'][\"roi_heads.box_predictor.bbox_pred.weight\"].shape)\n",
        "\n",
        "civil_role_real_test_coco = load_coco_data(civil_role_real_test_coco_path)\n",
        "role_model = load_model(role_model_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test json loc: /content/drive/MyDrive/111 Rendered.ai/RarePlanes/datasets/coco_data/civil_role_real_test_coco.json\n",
            "dict_keys(['annotations', 'images', 'categories'])\n",
            "Num images in civil role real test         : 2601\n",
            "classes in civil role real test        : [{'id': 0, 'name': 'civil_small'}, {'id': 1, 'name': 'civil_medium'}, {'id': 2, 'name': 'civil_large'}]\n",
            "Num bbox/instances in civil role real test : 6457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oP1gQUlTkN6",
        "outputId": "ee5c9b27-ee7d-4933-c784-84d37f8277f6"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTEI5_f55iaz"
      },
      "source": [
        "# Load Pretrained Faster-RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB_l6ZtC-XSG"
      },
      "source": [
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for bbox predication\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "# cfg.MODEL.WEIGHTS = \"/content/gdrive/MyDrive/RarePlanes/models/model_0043999.pth\" # faster rcnn for aircraft binary classification\n",
        "cfg.MODEL.WEIGHTS = role_model_dir # faster rcnn for civil role classification\n",
        "cfg.DATASETS.TEST = (\"civil_test\", )\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # 1 class for aircraft, 3 for civil role\n",
        "predictor = DefaultPredictor(cfg)\n",
        "fast_rcnn_model = build_model(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtGc4Ar_MtBU"
      },
      "source": [
        "# Train ResNet 50 on predicted instances\n",
        "Use predicted bbox and category_id from faster_cnn_model to finetune a ResNet50, because third-party DTD code only supports ResNet and ResNet is a backbone in Faster-RCNN. Extract the counterpart layers of ResNet from Faster-RCNN and load them into ResNet. Freeze these layers and only finetune the weights for last FC layer, because our ResNet50 only has 3 classes, not like 1000 classes from ImageNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmNxmJ6fPejw"
      },
      "source": [
        "## Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtrqBK407Lv3"
      },
      "source": [
        "# load cropped images and ann\n",
        "cropped_imgs_dir = \"/content/drive/MyDrive/111 Rendered.ai/data/cropped_civil_role_images/\"\n",
        "prediction_dict_df = pd.read_csv(cropped_imgs_dir + \"instances_prediction_info.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScadS2tXQlNc"
      },
      "source": [
        "# acc of un-finetined resnet50\n",
        "train_dir = cropped_imgs_dir\n",
        "batch_size = 1\n",
        "num_workers = 4\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "                                      train_dir,\n",
        "                                      transforms.Compose([\n",
        "                                          transforms.Resize(224),\n",
        "                                          transforms.CenterCrop(224),\n",
        "                                          transforms.ToTensor(),\n",
        "                                      ]))\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                          num_workers=num_workers, pin_memory=True, shuffle=True,\n",
        "                          drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WbpQV4fPh8E"
      },
      "source": [
        "## Load pretrained resnet 50 model whose weights = faster-rcnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGn0nB2tGOED"
      },
      "source": [
        "def matching_fpn2res(faster_rnn, res50):\n",
        "    fas2res = {\"res2\":\"layer1\", \"res3\":\"layer2\", \"res4\":\"layer3\", \"res5\":\"layer4\"}\n",
        "    frcnn_dict = defaultdict(list)\n",
        "    res50_dict = defaultdict(list)\n",
        "\n",
        "    for fas_layer_i in fas2res:\n",
        "        for k in faster_rnn[\"model\"]:\n",
        "          if fas_layer_i in k and \"weight\" in k and \"shortcut\" not in k:\n",
        "            frcnn_dict[fas_layer_i].append(k)\n",
        "        for k in res50.keys():\n",
        "          res_layer_i = fas2res[fas_layer_i]\n",
        "          if \"weight\" in k and res_layer_i in k and \"down\" not in k:\n",
        "            res50_dict[res_layer_i].append(k)\n",
        "\n",
        "    return frcnn_dict, res50_dict\n",
        "\n",
        "\n",
        "def flatten_dict(dic):\n",
        "    lst = []\n",
        "    for k,v in dic.items():\n",
        "        lst+=v\n",
        "    return lst\n",
        "\n",
        "\n",
        "def fpn2res_mapping(fas_lst, res50_lst):\n",
        "    map = {}\n",
        "    for i,k in enumerate(res50_lst):\n",
        "        map[fas_lst[i]] = k\n",
        "    return map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMvHytewGY47"
      },
      "source": [
        "# load pretrained faster_rcnn for weights extraction\n",
        "faster_rcnn = role_model\n",
        "# load pretrained resnet50\n",
        "resnet_model = resnet50(pretrained=False, num_classes=3)\n",
        "if not os.path.exists(models_file+\"pretrain_res50.pth\"):\n",
        "    data = request.urlopen('https://download.pytorch.org/models/resnet50-19c8e357.pth', timeout=15).read()\n",
        "    with open(models_file+\"pretrain_res50.pth\", 'wb') as f:\n",
        "        f.write(data)\n",
        "res50 = torch.load(models_file+\"pretrain_res50.pth\")\n",
        "\n",
        "#modify the last FC layer shapes to cater for our 3 classes\n",
        "res50['fc.weight'] = res50['fc.weight'][:3]\n",
        "res50['fc.bias'] = res50['fc.bias'][:3]\n",
        "# print(res50['fc.weight'].shape)\n",
        "# print(res50['fc.bias'].shape)\n",
        "\n",
        "# make model pth mapping\n",
        "frcnn_dict, res50_dict = matching_fpn2res(faster_rcnn, res50)\n",
        "fas_lst = flatten_dict(frcnn_dict)\n",
        "res50_lst = flatten_dict(res50_dict)\n",
        "mapping = fpn2res_mapping(fas_lst, res50_lst)\n",
        "\n",
        "# match dictionary keys betweeen faster rcnn + resnet50\n",
        "res50_by_fpn = res50\n",
        "for k in mapping:\n",
        "    res50_by_fpn[mapping[k]] = faster_rcnn[\"model\"][k]\n",
        "  \n",
        "# load our resnet_model with extracted weights from pretrained faster-rcnn\n",
        "resnet_model.load_state_dict(res50_by_fpn)\n",
        "# freeze all but last 2 params of ResNet50\n",
        "for i, param in enumerate(resnet_model.parameters()):\n",
        "    param.requires_grad = True if i in [159,160] else False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cnn5ZZ_PMld"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyYn6q-uEFsP"
      },
      "source": [
        "def train(model, train_loader, epoch, num_epoch, learning_rate, weight_decay, log_interval):\n",
        "    # Using sum reduction simply bc otherwise, the scale of the loss is too small;\n",
        "    # given that we always have 28*28 images, using sum/mean reduction wouldn't\n",
        "    # make a difference.\n",
        "    criteria = nn.CrossEntropyLoss(reduction='sum')\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    print('model train start')\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        print(f'i : {i}')\n",
        "        images, targets = data\n",
        "        targets -= 1\n",
        "\n",
        "        # send to device\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "        \n",
        "        # zero grad\n",
        "        optimizer.zero_grad()\n",
        "        # feed forward\n",
        "        outputs = model(images)\n",
        "\n",
        "        # print(targets.size)\n",
        "        # print(outputs.size)\n",
        "\n",
        "        # compute loss\n",
        "        # for denoising version, loss is between dirty images output and clean input!\n",
        "        loss = criteria(outputs, targets)\n",
        "        # print(type(loss))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # b\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % log_interval == 0:\n",
        "            print('Epoch [{}/{}] - Iter[{}/{}], Cross Entropy loss:{:.6f}'.format(\n",
        "                epoch + 1, num_epoch, i + 1,\n",
        "                len(train_loader.dataset) // batch_size, loss.item() / batch_size\n",
        "            ))\n",
        "\n",
        "def validate(model, valid_loader, best_val_loss):\n",
        "    total_loss = 0\n",
        "    criteria = nn.CrossEntropyLoss(reduction='sum')\n",
        "    model.eval()\n",
        "    for i, data in enumerate(valid_loader):\n",
        "        images, targets = data\n",
        "        targets -= 1\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criteria(outputs, targets)\n",
        "        total_loss += loss\n",
        "    \n",
        "    avg_loss = total_loss / (len(valid_loader) * batch_size)\n",
        "\n",
        "    print('\\nLoss per batch on validation set: {:.6f}'.format(avg_loss))\n",
        "\n",
        "    if avg_loss < best_val_loss:\n",
        "        save_path = '/content/gdrive/MyDrive/cropped_civil_role_images/'\n",
        "        best_val_loss = avg_loss\n",
        "        # Save best model\n",
        "        torch.save(model.state_dict(), save_path+\"/model_\"+str(best_val_loss))\n",
        "        print('Saved best model in the checkpoint directory\\n')\n",
        "    \n",
        "    return best_val_loss\n",
        "\n",
        "def predict(model, train_loader):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in tqdm(enumerate(train_loader)):\n",
        "\n",
        "        # if i % 500 == 0:\n",
        "        print(f'batch : {i + 1}')\n",
        "\n",
        "        images, targets = data\n",
        "        targets -= 1\n",
        "        # print(targets)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, axis = 1) + 1\n",
        "\n",
        "        # print(outputs)\n",
        "        # print(preds)\n",
        "\n",
        "        correct += (targets == preds).sum().item()\n",
        "        total += targets.size(0)\n",
        "    \n",
        "    print('Accuracy : %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HN9MbGJHEF3I",
        "outputId": "f87aaf70-85a2-48ce-efbb-0ef1ed18b07d"
      },
      "source": [
        "# If want to further finetune resnet_model, de-comment this cell block\n",
        "best_val_loss = float('inf')\n",
        "num_epoch = 50\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 0\n",
        "log_interval = 10\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"\n",
        "\n",
        "device = torch.device(dev)  \n",
        "\n",
        "resnet_model = resnet_model.to(dev)\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    start_time = datetime.datetime.now()\n",
        "    print('enter our_train() ...')\n",
        "    train(resnet_model, train_loader, epoch, num_epoch, learning_rate, weight_decay, log_interval)\n",
        "    end_time = datetime.datetime.now()\n",
        "    print(f'Trained this epoch using {(end_time - start_time).seconds} seconds')\n",
        "    # validate and save model if it's the best model so far\n",
        "    best_val_loss = validate(resnet_model, train_loader, best_val_loss)\n",
        "print('Training done; best validation loss {:.4f}'.format(best_val_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enter our_train() ...\n",
            "model train start\n",
            "i : 0\n",
            "i : 1\n",
            "i : 2\n",
            "i : 3\n",
            "i : 4\n",
            "i : 5\n",
            "i : 6\n",
            "i : 7\n",
            "i : 8\n",
            "i : 9\n",
            "Epoch [1/50] - Iter[10/7844], Cross Entropy loss:0.557822\n",
            "i : 10\n",
            "i : 11\n",
            "i : 12\n",
            "i : 13\n",
            "i : 14\n",
            "i : 15\n",
            "i : 16\n",
            "i : 17\n",
            "i : 18\n",
            "i : 19\n",
            "Epoch [1/50] - Iter[20/7844], Cross Entropy loss:0.007718\n",
            "i : 20\n",
            "i : 21\n",
            "i : 22\n",
            "i : 23\n",
            "i : 24\n",
            "i : 25\n",
            "i : 26\n",
            "i : 27\n",
            "i : 28\n",
            "i : 29\n",
            "Epoch [1/50] - Iter[30/7844], Cross Entropy loss:1.955780\n",
            "i : 30\n",
            "i : 31\n",
            "i : 32\n",
            "i : 33\n",
            "i : 34\n",
            "i : 35\n",
            "i : 36\n",
            "i : 37\n",
            "i : 38\n",
            "i : 39\n",
            "Epoch [1/50] - Iter[40/7844], Cross Entropy loss:0.058419\n",
            "i : 40\n",
            "i : 41\n",
            "i : 42\n",
            "i : 43\n",
            "i : 44\n",
            "i : 45\n",
            "i : 46\n",
            "i : 47\n",
            "i : 48\n",
            "i : 49\n",
            "Epoch [1/50] - Iter[50/7844], Cross Entropy loss:6.043296\n",
            "i : 50\n",
            "i : 51\n",
            "i : 52\n",
            "i : 53\n",
            "i : 54\n",
            "i : 55\n",
            "i : 56\n",
            "i : 57\n",
            "i : 58\n",
            "i : 59\n",
            "Epoch [1/50] - Iter[60/7844], Cross Entropy loss:0.005157\n",
            "i : 60\n",
            "i : 61\n",
            "i : 62\n",
            "i : 63\n",
            "i : 64\n",
            "i : 65\n",
            "i : 66\n",
            "i : 67\n",
            "i : 68\n",
            "i : 69\n",
            "Epoch [1/50] - Iter[70/7844], Cross Entropy loss:0.265424\n",
            "i : 70\n",
            "i : 71\n",
            "i : 72\n",
            "i : 73\n",
            "i : 74\n",
            "i : 75\n",
            "i : 76\n",
            "i : 77\n",
            "i : 78\n",
            "i : 79\n",
            "Epoch [1/50] - Iter[80/7844], Cross Entropy loss:0.105429\n",
            "i : 80\n",
            "i : 81\n",
            "i : 82\n",
            "i : 83\n",
            "i : 84\n",
            "i : 85\n",
            "i : 86\n",
            "i : 87\n",
            "i : 88\n",
            "i : 89\n",
            "Epoch [1/50] - Iter[90/7844], Cross Entropy loss:3.511543\n",
            "i : 90\n",
            "i : 91\n",
            "i : 92\n",
            "i : 93\n",
            "i : 94\n",
            "i : 95\n",
            "i : 96\n",
            "i : 97\n",
            "i : 98\n",
            "i : 99\n",
            "Epoch [1/50] - Iter[100/7844], Cross Entropy loss:0.872831\n",
            "i : 100\n",
            "i : 101\n",
            "i : 102\n",
            "i : 103\n",
            "i : 104\n",
            "i : 105\n",
            "i : 106\n",
            "i : 107\n",
            "i : 108\n",
            "i : 109\n",
            "Epoch [1/50] - Iter[110/7844], Cross Entropy loss:1.954164\n",
            "i : 110\n",
            "i : 111\n",
            "i : 112\n",
            "i : 113\n",
            "i : 114\n",
            "i : 115\n",
            "i : 116\n",
            "i : 117\n",
            "i : 118\n",
            "i : 119\n",
            "Epoch [1/50] - Iter[120/7844], Cross Entropy loss:0.052518\n",
            "i : 120\n",
            "i : 121\n",
            "i : 122\n",
            "i : 123\n",
            "i : 124\n",
            "i : 125\n",
            "i : 126\n",
            "i : 127\n",
            "i : 128\n",
            "i : 129\n",
            "Epoch [1/50] - Iter[130/7844], Cross Entropy loss:1.752826\n",
            "i : 130\n",
            "i : 131\n",
            "i : 132\n",
            "i : 133\n",
            "i : 134\n",
            "i : 135\n",
            "i : 136\n",
            "i : 137\n",
            "i : 138\n",
            "i : 139\n",
            "Epoch [1/50] - Iter[140/7844], Cross Entropy loss:0.116691\n",
            "i : 140\n",
            "i : 141\n",
            "i : 142\n",
            "i : 143\n",
            "i : 144\n",
            "i : 145\n",
            "i : 146\n",
            "i : 147\n",
            "i : 148\n",
            "i : 149\n",
            "Epoch [1/50] - Iter[150/7844], Cross Entropy loss:0.298066\n",
            "i : 150\n",
            "i : 151\n",
            "i : 152\n",
            "i : 153\n",
            "i : 154\n",
            "i : 155\n",
            "i : 156\n",
            "i : 157\n",
            "i : 158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-af39fd62c4b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enter our_train() ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Trained this epoch using {(end_time - start_time).seconds} seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-795510b05d62>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, epoch, num_epoch, learning_rate, weight_decay, log_interval)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'i : {i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzhS4U7Ovy76"
      },
      "source": [
        "## Loaded well_trained resnet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyj-AGPVv3Jg",
        "outputId": "f1a0f280-6e17-40b1-a286-fb34306461ac"
      },
      "source": [
        "# finetuned model is at /content/gdrive/MyDrive/cropped_civil_role_images/model_tensor(0.5385, device='cuda:0', grad_fn=<DivBackward0>)\n",
        "resnet_model.load_state_dict(torch.load(\"/content/gdrive/MyDrive/cropped_civil_role_images/model_tensor(0.5385, device='cuda:0', grad_fn=<DivBackward0>)\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    }
  ]
}